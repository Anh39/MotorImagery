{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import biosig\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import math\n",
    "from typing import Literal\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mne.decoding import CSP\n",
    "from wave_dataloader import MotorImageryDataset, EVENT_TYPES, Util\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([32766,   276,   277,  1081])\n"
     ]
    }
   ],
   "source": [
    "dataloader = Util.read_data(\"B0101T.gdf\", n_workers=0, bsz=4, item_length=500)\n",
    "for data, label in dataloader:\n",
    "    break\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "fs = 250\n",
    "channels = 6\n",
    "num_input = 1\n",
    "num_class = 14\n",
    "signal_length = 500\n",
    "kernel_size_1 = (1, round(fs/2))\n",
    "kernel_size_2 = (channels, 1)\n",
    "kernel_size_3 = (1, round(fs/8))\n",
    "kernel_size_4 = (1, 1)\n",
    "\n",
    "kernel_avg_pool_1 = (1, 4)\n",
    "kernel_avg_poll_2 = (1, 8)\n",
    "dropout_rate = 0.2\n",
    "\n",
    "ks0 = int(round((kernel_size_1[0]-1)/2))\n",
    "ks1 = int(round((kernel_size_1[0]-1)/2))\n",
    "kernel_padding_1 = (ks0, ks1 - 1)\n",
    "ks0 = int(round((kernel_size_3[0]-1)/2))\n",
    "ks1 = int(round((kernel_size_3[0]-1)/2))\n",
    "kernel_padding_3 = (ks0, ks1 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, \n",
    "        channels: int = 6,\n",
    "        sampling_rate: int = 250,\n",
    "        dropout_rate: float = 0.5,\n",
    "        kernel_length: int = 64,\n",
    "        f1: int = 8,\n",
    "        D: int = 2,\n",
    "        f2:int = 16,\n",
    "        norm_rate: float = 0.25,\n",
    "        output_size: int = 1\n",
    "    ):\n",
    "        super(EEGNet, self).__init__()\n",
    "        #Norm\n",
    "        #Block 1\n",
    "        # self.block1 = nn.Sequential(\n",
    "        #     nn.BatchNorm2d(f1),\n",
    "        #     nn.Conv2d(f1, f1 * D, kernel_size=(channels, 1), groups=f1, bias=False),\n",
    "        #     nn.BatchNorm2d(f1 * D),\n",
    "        #     nn.ELU(),\n",
    "        #     nn.AvgPool2d(kernel_size=(1,4)),\n",
    "        #     nn.Dropout(p=dropout_rate)\n",
    "        # )\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=channels,\n",
    "            out_channels=f1,\n",
    "            kernel_size=(1, kernel_length),\n",
    "            padding='same',\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(f1)\n",
    "        self.conv2 = nn.Conv2d(f1, f1 * D, kernel_size=(channels, 1), groups=f1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(f1 * D)\n",
    "        self.act = nn.ELU()\n",
    "        self.avg1 = nn.AvgPool2d(kernel_size=(1, 4))\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        #Block 2\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(f1 * D, f2, kernel_size=(1, 16), padding='same', bias=False),\n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(1, 8)),\n",
    "            nn.Dropout2d(p=dropout_rate)    \n",
    "        )\n",
    "        \n",
    "        #FFW\n",
    "        self.ffw = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(f2 * (sampling_rate // 4) // 8, output_size),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        #Norm\n",
    "        #elu\n",
    "        #AvgPool2D\n",
    "        #dropout\n",
    "        #SepConv2D\n",
    "        #Norm\n",
    "        #Elu\n",
    "        #AvgPool2d\n",
    "        #dropout\n",
    "        #flat\n",
    "        #dense\n",
    "        #softmax\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x = self.block1(x)\n",
    "        print(\"I\", x.shape)\n",
    "        x = self.conv1(x)\n",
    "        print(\"CON1\", x.shape)\n",
    "        x = self.bn1(x)\n",
    "        print(\"BN\", x.shape)\n",
    "        x = self.conv2(x)\n",
    "        print(\"CON2\", x.shape)\n",
    "        x = self.bn2(x)\n",
    "        print(\"BN\", x.shape)\n",
    "        x = self.act(x)\n",
    "        print(\"ACT\", x.shape)\n",
    "        x = self.avg1(x)\n",
    "        print(\"AVG\", x.shape)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.block2(x)\n",
    "        x = self.ffw(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data format [trials, channels, samples, kernels]\n",
    "kernels = 1\n",
    "channels = 6\n",
    "samples = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 500, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "data: torch.Tensor = data.unsqueeze(3)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.permute(0,2,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 6, 500, 1])\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "#data format [trials, channels, samples, kernels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I torch.Size([4, 6, 500, 1])\n",
      "CON1 torch.Size([4, 8, 500, 1])\n",
      "BN torch.Size([4, 8, 500, 1])\n",
      "CON2 torch.Size([4, 16, 495, 1])\n",
      "BN torch.Size([4, 16, 495, 1])\n",
      "ACT torch.Size([4, 16, 495, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (16x495x1). Calculated output size: (16x495x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m EEGNet(\n\u001b[0;32m      2\u001b[0m     channels\u001b[38;5;241m=\u001b[39mchannels,\n\u001b[0;32m      3\u001b[0m     sampling_rate\u001b[38;5;241m=\u001b[39msamples,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m     10\u001b[0m )\n\u001b[1;32m---> 11\u001b[0m ouput \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 78\u001b[0m, in \u001b[0;36mEEGNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     76\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(x)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACT\u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 78\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mavg1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAVG\u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     80\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n",
      "File \u001b[1;32mc:\\Users\\Anh\\.conda\\envs\\data\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Anh\\.conda\\envs\\data\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Anh\\.conda\\envs\\data\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py:641\u001b[0m, in \u001b[0;36mAvgPool2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mavg_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount_include_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdivisor_override\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given input size: (16x495x1). Calculated output size: (16x495x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "model = EEGNet(\n",
    "    channels=channels,\n",
    "    sampling_rate=samples,\n",
    "    output_size=14,\n",
    "    kernel_length=32,\n",
    "    f1=8,\n",
    "    D=2,\n",
    "    f2=16,\n",
    "    dropout_rate=0.5\n",
    ")\n",
    "ouput = model.forward(data.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
